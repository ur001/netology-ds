{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import CosineRecommender, bm25_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/Users/ur001/Documents/Datasets/lastfm-dataset-360K\"\n",
    "dest_data_dir = \"/Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path): \n",
    "    return pd.read_table(\n",
    "        os.path.join(path, \"usersha1-artmbid-artname-plays.tsv\"),\n",
    "        usecols=[0, 1, 2, 3],\n",
    "        names=['user', 'artist', 'artist_name', 'plays'],\n",
    "    )\n",
    "\n",
    "def prepare_data(data):\n",
    "    \"\"\"Возвращает подготовленные данные и словарь артистов\"\"\"\n",
    "    # Заменяем отсутствующие значения идентификаторов исполнителя на его имя\n",
    "    print(\"Filling na artists...\")\n",
    "    data.dropna(subset=['artist_name'], inplace=True)\n",
    "    empty_artist = data.artist.isnull()\n",
    "    data.loc[empty_artist, 'artist'] = data.loc[empty_artist, 'artist_name']\n",
    "    \n",
    "    # Преобразуем пользователей и исполнителей в числа\n",
    "    print(\"Encoding artits and users...\")\n",
    "    data['artist_id'] = data.artist.astype(\"category\").cat.codes.copy() + 1\n",
    "    data['user_id'] = data.user.astype(\"category\").cat.codes.copy() + 1\n",
    "    \n",
    "    # Составляем словарь исполнителей\n",
    "    print(\"Saving atists dict...\")\n",
    "    artists = dict(data.groupby('artist_id').artist_name.first())\n",
    "    return data[['user_id', 'artist_id', 'plays']], artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, size=0.2):\n",
    "    data_train, data_test = train_test_split(data, test_size=size)\n",
    "    test_user_set = set(data_test.user_id.unique())\n",
    "    train_user_set = set(data_train.user_id.unique())\n",
    "    # Оставляем только пользователей которые есть одновременно в тестовой и обучающей выборке\n",
    "    user_ids_to_exclude = (test_user_set - train_user_set).union(train_user_set - test_user_set)\n",
    "    return (\n",
    "        data_train[~data_train.user_id.isin(user_ids_to_exclude)], \n",
    "        data_test[~data_test.user_id.isin(user_ids_to_exclude)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data(path, name, data, columns=[\"user_id\", \"artist_id\", \"plays\"]):\n",
    "    file_name = os.path.join(path, name + \".tsv\")\n",
    "    data[columns].to_csv(file_name, sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_coo_matrix(data):\n",
    "    \"\"\"Создаёт разреженную матрицу item*user\"\"\"\n",
    "    return coo_matrix((\n",
    "        data.plays.astype(np.double),\n",
    "        (data.artist_id, data.user_id)\n",
    "    ))\n",
    "\n",
    "def sparse_info(sparse_matrix):\n",
    "    \"\"\"функция, которая красиво печатает информацию о разреженных матрицах\"\"\"\n",
    "    print(\"Размерности матрицы: {}\".format(sparse_matrix.shape))\n",
    "    print(\"Ненулевых элементов в матрице: {}\".format(sparse_matrix.nnz))\n",
    "    print(\"Доля ненулевых элементов: {}\".format(\n",
    "        sparse_matrix.nnz / sparse_matrix.shape[0] / sparse_matrix.shape[1]\n",
    "    ))\n",
    "    print(\"Среднее значение ненулевых элементов: {}\".format(sparse_matrix.data.mean()))\n",
    "    print(\"Максимальное значение ненулевых элементов: {}\".format(sparse_matrix.data.max()))\n",
    "    print(\"Минимальное значение ненулевых элементов: {}\".format(sparse_matrix.data.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_user_recommendations(model, data_train_coo, data_test, path, model_name):\n",
    "    \"\"\"Генерирует рекомендации для каждого пользователя и сохраняет их в файл для проверки mrec-ом\"\"\"\n",
    "    user_plays = data_train_coo.T.tocsr()\n",
    "    file_name = \"test.{}.tsv.recs.tsv\".format(model_name)\n",
    "    # Получаем столько рекомендаций, сколько записей у пользователя в тестовой выборке, но не меньше 3\n",
    "    user_rec_counts = dict(data_test.user_id.value_counts())\n",
    "    user_rec_counts = {user_id: max(10, int(N)) for user_id, N in user_rec_counts.items()}\n",
    "    with open(os.path.join(path, file_name), \"w\") as output_file:\n",
    "        for user_id in tqdm_notebook(data_test.user_id.unique()):\n",
    "            for artist_id, score in model.recommend(user_id, user_plays, N=user_rec_counts[user_id]):\n",
    "                output_file.write(\"{}\\t{}\\t{}\\n\".format(user_id, artist_id, score))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_artist(artists, name_prefix):\n",
    "    \"\"\"Поиск по базе исполнителей: выводит список всех начинающихся с переданного префикса\"\"\"\n",
    "    for artist_id, artist_name in artists.items():\n",
    "        if artist_name.lower().startswith(name_prefix):\n",
    "            print(\"[{}]\\t{}\".format(artist_id, artist_name))\n",
    "            \n",
    "def find_similar_artists(model, artist_id, artists, count=10):\n",
    "    \"\"\"Выводит список похожих исполнителей\"\"\"\n",
    "    print(\"Similar to {}:\".format(artists[artist_id]))\n",
    "    print(\"-------------------------------\")\n",
    "    for similar_artist_id, score in model.similar_items(artist_id, count):\n",
    "        print(\"{:.3f}\\t{}\".format(score, artists[similar_artist_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_src = load_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling na artists...\n",
      "Encoding artits and users...\n",
      "Saving atists dict...\n"
     ]
    }
   ],
   "source": [
    "data, artists = prepare_data(data_src.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>plays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39710</td>\n",
       "      <td>2137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>211105</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>135574</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40727</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>143198</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  artist_id  plays\n",
       "0        1      39710   2137\n",
       "1        1     211105   1099\n",
       "2        1     135574    897\n",
       "3        1      40727    717\n",
       "4        1     143198    706"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14025188, 3), (3507072, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = split_data(data, 0.2)\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>plays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6300863</th>\n",
       "      <td>128940</td>\n",
       "      <td>5546</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9157993</th>\n",
       "      <td>187350</td>\n",
       "      <td>165235</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6457294</th>\n",
       "      <td>132137</td>\n",
       "      <td>94933</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271168</th>\n",
       "      <td>107872</td>\n",
       "      <td>184815</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7087033</th>\n",
       "      <td>144995</td>\n",
       "      <td>178286</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  artist_id  plays\n",
       "6300863   128940       5546    276\n",
       "9157993   187350     165235     37\n",
       "6457294   132137      94933    291\n",
       "5271168   107872     184815     48\n",
       "7087033   144995     178286     48"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data(dest_data_dir, 'train', data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_coo = make_coo_matrix(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерности матрицы: (268590, 358869)\n",
      "Ненулевых элементов в матрице: 14025188\n",
      "Доля ненулевых элементов: 0.00014550667199783102\n",
      "Среднее значение ненулевых элементов: 215.0617464806889\n",
      "Максимальное значение ненулевых элементов: 419157.0\n",
      "Минимальное значение ненулевых элементов: 1.0\n"
     ]
    }
   ],
   "source": [
    "sparse_info(data_train_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_csr = data_train_coo.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# строим матрицу схожести по косинусной мере\n",
    "models = {}\n",
    "models['knn_cosine'] = CosineRecommender()\n",
    "models['knn_cosine'].fit(data_train_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data(dest_data_dir, 'test.knn_cosine', data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128602]\taphex twin & céline eia\n",
      "[128603]\taphex twin & m-ziq (aka rich & mike)\n",
      "[128604]\taphex twin & squarepusher\n",
      "[128605]\taphex twin & µ-ziq (mike & rich)\n",
      "[128606]\taphex twin & µ-ziq - mike and rich\n",
      "[128607]\taphex twin (aka afx)\n",
      "[128608]\taphex twin (aka caustic window)\n",
      "[128609]\taphex twin (aka polygon window)\n",
      "[128610]\taphex twin (aka universal indicator)\n",
      "[128611]\taphex twin - power-pill\n",
      "[128612]\taphex twin ft. photek & autechre\n",
      "[128613]\taphex twin vs luke vibert\n",
      "[128614]\taphex twin vs run jeremy\n",
      "[128615]\taphex twin/afx\n",
      "[128616]\taphex twin/luke vibert\n",
      "[128617]\taphex twin/richard james\n",
      "[210592]\taphex twin\n"
     ]
    }
   ],
   "source": [
    "# Попробуем найти похожих исполнителей на Aphex Twin, чтобы убедиться что рекомендации вообще работают\n",
    "search_artist(artists, 'aphex twin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to aphex twin:\n",
      "-------------------------------\n",
      "1.000\taphex twin\n",
      "0.436\tafx\n",
      "0.354\tケンイシイ\n",
      "0.353\tmagnat\n",
      "0.284\tsquarepusher\n",
      "0.272\tpolygon window\n",
      "0.266\tautechre\n",
      "0.213\tboards of canada\n",
      "0.205\tgts feat. melodie sexton\n",
      "0.198\tapollon / muslimgauze\n"
     ]
    }
   ],
   "source": [
    "aphex_twin_id = 210592\n",
    "find_similar_artists(models['knn_cosine'], aphex_twin_id, artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a11cc8b0034cc380de394d05926efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=358538), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Создаём рекомендации для всех тестовых пользователей\n",
    "make_user_recommendations(models['knn_cosine'], data_train_csr, data_test, dest_data_dir, 'knn_cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-12-05 01:15:40,695] INFO: processing /Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest/test.knn_cosine.tsv...\n",
      "None\n",
      "mrr            0.1176 +/- 0.0000\n",
      "prec@5         0.0427 +/- 0.0000\n",
      "prec@10        0.0348 +/- 0.0000\n",
      "prec@15        0.0254 +/- 0.0000\n",
      "prec@20        0.0192 +/- 0.0000\n"
     ]
    }
   ],
   "source": [
    "!/Users/ur001/.pyenv/versions/netology1/bin/mrec_evaluate \\\n",
    "    --input_format=tsv --test_input_format=tsv \\\n",
    "    --train /Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest/test.knn_cosine.tsv \\\n",
    "    --recsdir /Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тренируем ALS-модель\n",
    "data_train_bm25 = bm25_weight(data_train_coo, K1=100, B=0.8).tocsr()\n",
    "models['als'] = AlternatingLeastSquares(factors=128, iterations=20, regularization=0.001)\n",
    "models['als'].fit(data_train_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to aphex twin:\n",
      "-------------------------------\n",
      "1.000\taphex twin\n",
      "0.996\tboards of canada\n",
      "0.992\tsquarepusher\n",
      "0.986\tamon tobin\n",
      "0.981\tautechre\n",
      "0.980\tdj shadow\n",
      "0.980\tburial\n",
      "0.980\tkraftwerk\n",
      "0.979\tbjörk\n",
      "0.978\tportishead\n"
     ]
    }
   ],
   "source": [
    "find_similar_artists(models['als'], aphex_twin_id, artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data(dest_data_dir, 'test.als', data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534c4dbb1c4c4a5fb8e55f25d9b9b7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=358538), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_user_recommendations(models['als'], data_train_bm25, data_test, dest_data_dir, 'als')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-12-05 04:40:37,789] INFO: processing /Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest/test.als.tsv...\n",
      "None\n",
      "mrr            0.3166 +/- 0.0000\n",
      "prec@5         0.1392 +/- 0.0000\n",
      "prec@10        0.1110 +/- 0.0000\n",
      "prec@15        0.0804 +/- 0.0000\n",
      "prec@20        0.0608 +/- 0.0000\n"
     ]
    }
   ],
   "source": [
    "!/Users/ur001/.pyenv/versions/netology1/bin/mrec_evaluate \\\n",
    "    --input_format=tsv --test_input_format=tsv \\\n",
    "    --train /Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest/test.als.tsv \\\n",
    "    --recsdir /Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from implicit.approximate_als import NMSLibAlternatingLeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models['als_nmslib'] = NMSLibAlternatingLeastSquares(factors=128)\n",
    "models['als_nmslib'].fit(data_train_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to aphex twin:\n",
      "-------------------------------\n",
      "1.000\taphex twin\n",
      "0.996\tboards of canada\n",
      "0.992\tautechre\n",
      "0.986\tamon tobin\n",
      "0.983\tdj shadow\n",
      "0.981\tsquarepusher\n",
      "0.981\tburial\n",
      "0.979\tmassive attack\n",
      "0.979\tbjörk\n",
      "0.978\torbital\n"
     ]
    }
   ],
   "source": [
    "find_similar_artists(models['als_nmslib'], aphex_twin_id, artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c804ab3e24164954a9bdb847f9b2a827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=358538), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_user_recommendations(models['als_nmslib'], data_train_bm25, data_test, dest_data_dir, 'als_nmslib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data(dest_data_dir, 'test.als_nmslib', data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2017-12-05 04:48:42,178] INFO: processing /Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest/test.als_nmslib.tsv...\n",
      "None\n",
      "mrr            0.2426 +/- 0.0000\n",
      "prec@5         0.1043 +/- 0.0000\n",
      "prec@10        0.0818 +/- 0.0000\n",
      "prec@15        0.0590 +/- 0.0000\n",
      "prec@20        0.0446 +/- 0.0000\n"
     ]
    }
   ],
   "source": [
    "!/Users/ur001/.pyenv/versions/netology1/bin/mrec_evaluate \\\n",
    "    --input_format=tsv --test_input_format=tsv \\\n",
    "    --train /Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest/test.als_nmslib.tsv \\\n",
    "    --recsdir /Users/ur001/Documents/Datasets/lastfm-dataset-360K/dest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
